{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "from self_training import SelfTraining\n",
    "from utils import generate_data, ToArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_PER_CAT = 20 \n",
    "\n",
    "# Same parameters for each experiment\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "SCORING = 'micro'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>from_</th>\n",
       "      <th>to</th>\n",
       "      <th>attachment_names</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translation of articles</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>enron.com;enron.com;enron.com;enron.com;enron....</td>\n",
       "      <td>klay.nsf</td>\n",
       "      <td>\\n\\nKaren\\n\\nHere it is!\\n\\nPlenty of good Hou...</td>\n",
       "      <td>1999-10-18 08:47:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>dfossum.nsf</td>\n",
       "      <td>In anticipation of potential litigation involv...</td>\n",
       "      <td>2001-03-05 16:23:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>enron.com;enron.com</td>\n",
       "      <td>dfossum.nsf</td>\n",
       "      <td>Julia and Steve--here are some questions I've ...</td>\n",
       "      <td>2001-03-06 08:59:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>enron.com;enron.com</td>\n",
       "      <td>DFOSSUM (Non-Privileged).pst</td>\n",
       "      <td>Julia and Steve--here are some questions I've ...</td>\n",
       "      <td>2001-03-06 19:59:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>enron.com</td>\n",
       "      <td>DFOSSUM (Non-Privileged).pst</td>\n",
       "      <td>In anticipation of potential litigation involv...</td>\n",
       "      <td>2001-03-06 03:23:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             subject      from_  \\\n",
       "0                            Translation of articles  enron.com   \n",
       "1  TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...  enron.com   \n",
       "2  TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...  enron.com   \n",
       "3  TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...  enron.com   \n",
       "4  TW Gas Sales: PRIVILEGED AND CONFIDENTIAL ATTO...  enron.com   \n",
       "\n",
       "                                                  to  \\\n",
       "0  enron.com;enron.com;enron.com;enron.com;enron....   \n",
       "1                                          enron.com   \n",
       "2                                enron.com;enron.com   \n",
       "3                                enron.com;enron.com   \n",
       "4                                          enron.com   \n",
       "\n",
       "               attachment_names  \\\n",
       "0                      klay.nsf   \n",
       "1                   dfossum.nsf   \n",
       "2                   dfossum.nsf   \n",
       "3  DFOSSUM (Non-Privileged).pst   \n",
       "4  DFOSSUM (Non-Privileged).pst   \n",
       "\n",
       "                                                body                 date  \\\n",
       "0  \\n\\nKaren\\n\\nHere it is!\\n\\nPlenty of good Hou...  1999-10-18 08:47:00   \n",
       "1  In anticipation of potential litigation involv...  2001-03-05 16:23:00   \n",
       "2  Julia and Steve--here are some questions I've ...  2001-03-06 08:59:00   \n",
       "3  Julia and Steve--here are some questions I've ...  2001-03-06 19:59:00   \n",
       "4  In anticipation of potential litigation involv...  2001-03-06 03:23:00   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/complete_enron.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of the dataset with labeled and unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.body\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled data PER category: (array([0, 1, 2, 3, 4, 5]), array([20, 20, 20, 20, 20, 20]))\n"
     ]
    }
   ],
   "source": [
    "u_index, l_index = generate_data(X, y, NB_PER_CAT, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.loc[l_index], y.loc[l_index], test_size=TEST_SIZE, stratify=y.loc[l_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_u = pd.concat([X_train, X.loc[u_index]], axis=0)\n",
    "y_train_u = pd.concat([y_train, pd.Series([-1] * len(u_index))], axis=0)\n",
    "\n",
    "X_train_u.reset_index(drop=True, inplace=True)\n",
    "y_train_u.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_train, y_train = X_train_u, y_train_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of the vectorizer to create vector for each mail *(arbitrary hyper-parameters)*.\n",
    "- Creation of the semi-supervised wrapper method classifier which is using *LogisticRegression* classifier *(arbitrary hyper-parameters)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=\"word\",\n",
    "                            ngram_range=(1,3),\n",
    "                            max_features=5000)\n",
    "\n",
    "classifier = SelfTraining(learner=LogisticRegression(), \n",
    "                          iterations_nb=20, \n",
    "                          pool_size=50, \n",
    "                          training_way=2, \n",
    "                          replacement=True, \n",
    "                          random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creation of the pipeline and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...bose=0, warm_start=False),\n",
       "       pool_size=50, random_state=42, replacement=True, training_way=2))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testing model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4583333333333333"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=SCORING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_TODELETE",
   "language": "python",
   "name": "env_todelete"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
